{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.sql.functions import when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\n",
    "    \"HeartDiseaseClassification\"\n",
    ").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "df = spark.read.option(\n",
    "    \"delimiter\", \" \"\n",
    ").csv('data/heart.dat', inferSchema=True, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "new_column_names = [\n",
    "    'year',\n",
    "    'sex',\n",
    "    'tPain',\n",
    "    'restPressure', \n",
    "    'colesterol',\n",
    "    'bloodSugarL120', \n",
    "    'electrocardioRest',\n",
    "    'maxHeartRate', \n",
    "    'angina',\n",
    "    'oldPeak',\n",
    "    'stSlope', \n",
    "    'numVessels',\n",
    "    'thal'\n",
    "]\n",
    "for i in range(len(new_column_names)):\n",
    "    df = df.withColumnRenamed(df.columns[i], new_column_names[i])\n",
    "df = df.drop(df.columns[-1])\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\n",
    "    'sick',\n",
    "    when((df['thal'] == 3) | (df['thal'] == 6), 0).otherwise(1)\n",
    ")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.transform(\n",
    "    lambda df: df.withColumn(\n",
    "        'newSick',\n",
    "        when((df['thal'] == 3) | (df['thal'] == 6), 0).otherwise(1))\n",
    ")\n",
    "\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop newSick column\n",
    "df = df.drop('newSick')\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble all the features into a single vector\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\n",
    "        'year', 'sex', 'tPain', 'restPressure',\n",
    "        'colesterol', 'bloodSugarL120', 'electrocardioRest',\n",
    "        'maxHeartRate', 'angina', 'oldPeak', 'stSlope',\n",
    "        'numVessels'\n",
    "    ],\n",
    "    outputCol='features'\n",
    ")\n",
    "\n",
    "df = assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the 'features' and 'new_column' for the model\n",
    "model_data = df.select('features', 'sick')\n",
    "\n",
    "# Rename 'new_column' to 'label' as required by MLlib\n",
    "model_data = model_data.withColumnRenamed('sick', 'label')\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_data, test_data = model_data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Logistic Regression model and fit it to the training data\n",
    "lr = LogisticRegression()\n",
    "lr_model = lr.fit(train_data)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = lr_model.transform(test_data)\n",
    "\n",
    "# Show some predictions\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
